/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (17) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (33) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (65) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (129) may be set too low.
  warnings.warn(
[Step]: 200 | [Train losses]: {'l_g': tensor(1.2348), 'l_d': tensor(0.4501), 'l_t': tensor(0.2105), 'l_f': tensor(5.5537e-06), 'l_w': tensor(65.5605), 'l_feat': tensor(0.4283)}
[Step]: 200 | [Valid losses]: {'val_l_t': tensor(0.2469), 'sdr_tt': tensor(6.4858)}
[Step]: 400 | [Train losses]: {'l_g': tensor(1.1764), 'l_d': tensor(0.4783), 'l_t': tensor(0.3200), 'l_f': tensor(1.4428e-05), 'l_w': tensor(84.4845), 'l_feat': tensor(0.5532)}
[Step]: 400 | [Valid losses]: {'val_l_t': tensor(0.2480), 'sdr_tt': tensor(6.5920)}
[Step]: 600 | [Train losses]: {'l_g': tensor(1.5246), 'l_d': tensor(0.4200), 'l_t': tensor(0.2396), 'l_f': tensor(9.4405e-06), 'l_w': tensor(77.7321), 'l_feat': tensor(0.4755)}
[Step]: 600 | [Valid losses]: {'val_l_t': tensor(0.2382), 'sdr_tt': tensor(6.6623)}
[Step]: 800 | [Train losses]: {'l_g': tensor(1.4981), 'l_d': tensor(0.4397), 'l_t': tensor(0.2382), 'l_f': tensor(8.2749e-06), 'l_w': tensor(83.8492), 'l_feat': tensor(0.4716)}
[Step]: 800 | [Valid losses]: {'val_l_t': tensor(0.2428), 'sdr_tt': tensor(6.6501)}
[Step]: 1000 | [Train losses]: {'l_g': tensor(1.5154), 'l_d': tensor(0.4117), 'l_t': tensor(0.2216), 'l_f': tensor(6.2522e-06), 'l_w': tensor(74.7135), 'l_feat': tensor(0.4591)}
[Step]: 1000 | [Valid losses]: {'val_l_t': tensor(0.2396), 'sdr_tt': tensor(6.6976)}
[Step]: 1200 | [Train losses]: {'l_g': tensor(1.4136), 'l_d': tensor(0.4321), 'l_t': tensor(0.3113), 'l_f': tensor(1.4887e-05), 'l_w': tensor(100.3747), 'l_feat': tensor(0.5465)}
[Step]: 1200 | [Valid losses]: {'val_l_t': tensor(0.2464), 'sdr_tt': tensor(6.6591)}
[Step]: 1400 | [Train losses]: {'l_g': tensor(1.5784), 'l_d': tensor(0.4545), 'l_t': tensor(0.2437), 'l_f': tensor(7.6303e-06), 'l_w': tensor(90.9482), 'l_feat': tensor(0.4828)}
[Step]: 1400 | [Valid losses]: {'val_l_t': tensor(0.2417), 'sdr_tt': tensor(6.6981)}
[Step]: 1600 | [Train losses]: {'l_g': tensor(1.7426), 'l_d': tensor(0.5202), 'l_t': tensor(0.2560), 'l_f': tensor(1.0215e-05), 'l_w': tensor(87.2500), 'l_feat': tensor(0.4732)}
[Step]: 1600 | [Valid losses]: {'val_l_t': tensor(0.2392), 'sdr_tt': tensor(6.7882)}
[Step]: 1800 | [Train losses]: {'l_g': tensor(1.5459), 'l_d': tensor(0.4473), 'l_t': tensor(0.2475), 'l_f': tensor(8.7762e-06), 'l_w': tensor(96.8784), 'l_feat': tensor(0.4844)}
[Step]: 1800 | [Valid losses]: {'val_l_t': tensor(0.2460), 'sdr_tt': tensor(6.6812)}
[Step]: 2000 | [Train losses]: {'l_g': tensor(1.4990), 'l_d': tensor(0.4112), 'l_t': tensor(0.2384), 'l_f': tensor(8.5597e-06), 'l_w': tensor(88.3869), 'l_feat': tensor(0.4800)}
[Step]: 2000 | [Valid losses]: {'val_l_t': tensor(0.2402), 'sdr_tt': tensor(6.7139)}
[Step]: 2200 | [Train losses]: {'l_g': tensor(2.3986), 'l_d': tensor(0.6105), 'l_t': tensor(0.2747), 'l_f': tensor(1.1232e-05), 'l_w': tensor(118.1155), 'l_feat': tensor(0.4881)}
[Step]: 2200 | [Valid losses]: {'val_l_t': tensor(0.2403), 'sdr_tt': tensor(6.6695)}
[Step]: 2400 | [Train losses]: {'l_g': tensor(1.4655), 'l_d': tensor(0.4065), 'l_t': tensor(0.2662), 'l_f': tensor(9.1013e-06), 'l_w': tensor(98.0721), 'l_feat': tensor(0.4905)}
[Step]: 2400 | [Valid losses]: {'val_l_t': tensor(0.2410), 'sdr_tt': tensor(6.6767)}
[Step]: 2600 | [Train losses]: {'l_g': tensor(1.5245), 'l_d': tensor(0.4033), 'l_t': tensor(0.2449), 'l_f': tensor(8.2056e-06), 'l_w': tensor(92.1678), 'l_feat': tensor(0.4761)}
[Step]: 2600 | [Valid losses]: {'val_l_t': tensor(0.2393), 'sdr_tt': tensor(6.7434)}
[Step]: 2800 | [Train losses]: {'l_g': tensor(1.5061), 'l_d': tensor(0.4083), 'l_t': tensor(0.2516), 'l_f': tensor(8.9991e-06), 'l_w': tensor(93.0995), 'l_feat': tensor(0.4848)}
[Step]: 2800 | [Valid losses]: {'val_l_t': tensor(0.2391), 'sdr_tt': tensor(6.7486)}
[Step]: 3000 | [Train losses]: {'l_g': tensor(1.5250), 'l_d': tensor(0.4078), 'l_t': tensor(0.2403), 'l_f': tensor(7.7339e-06), 'l_w': tensor(105.6939), 'l_feat': tensor(0.4679)}
[Step]: 3000 | [Valid losses]: {'val_l_t': tensor(0.2484), 'sdr_tt': tensor(6.6486)}
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/dist_train.py", line 443, in <module>
    l_f = melspec_loss(s, s_hat, gpu_rank, range(5,12))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/dist_train.py", line 114, in melspec_loss
    mel_transform = transforms.MelSpectrogram(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py", line 638, in __init__
    self.mel_scale = MelScale(
                     ^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/transforms/_transforms.py", line 399, in __init__
    fb = F.melscale_fbanks(n_stft, self.f_min, self.f_max, self.n_mels, self.sample_rate, self.norm, self.mel_scale)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py", line 575, in melscale_fbanks
    if (fb.max(dim=0).values == 0.0).any():
        ^^^^^^^^^^^^^
KeyboardInterrupt