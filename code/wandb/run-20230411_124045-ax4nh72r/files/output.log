/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (17) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (33) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (65) may be set too low.
  warnings.warn(
/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (129) may be set too low.
  warnings.warn(
[Step]: 200 | [Train losses]: {'l_g': tensor(0.9819), 'l_d': tensor(0.6409), 'l_t': tensor(0.5223), 'l_f': tensor(0.0001), 'l_w': tensor(111.3102), 'l_feat': tensor(1.0871)}
[Step]: 200 | [Valid losses]: {'val_l_t': tensor(0.4826), 'sdr_tt': tensor(2.1746)}
[Step]: 400 | [Train losses]: {'l_g': tensor(1.1372), 'l_d': tensor(0.4981), 'l_t': tensor(0.5160), 'l_f': tensor(0.0001), 'l_w': tensor(96.1449), 'l_feat': tensor(0.9044)}
[Step]: 400 | [Valid losses]: {'val_l_t': tensor(0.4542), 'sdr_tt': tensor(2.8169)}
[Step]: 600 | [Train losses]: {'l_g': tensor(1.4600), 'l_d': tensor(0.4297), 'l_t': tensor(0.4413), 'l_f': tensor(6.9164e-05), 'l_w': tensor(86.3448), 'l_feat': tensor(0.8542)}
[Step]: 600 | [Valid losses]: {'val_l_t': tensor(0.4275), 'sdr_tt': tensor(3.3900)}
[Step]: 800 | [Train losses]: {'l_g': tensor(1.4953), 'l_d': tensor(0.4206), 'l_t': tensor(0.4176), 'l_f': tensor(6.5053e-05), 'l_w': tensor(78.5931), 'l_feat': tensor(0.8149)}
[Step]: 800 | [Valid losses]: {'val_l_t': tensor(0.4165), 'sdr_tt': tensor(3.5274)}
[Step]: 1000 | [Train losses]: {'l_g': tensor(1.5570), 'l_d': tensor(0.3830), 'l_t': tensor(0.3897), 'l_f': tensor(4.7114e-05), 'l_w': tensor(70.6151), 'l_feat': tensor(0.7769)}
[Step]: 1000 | [Valid losses]: {'val_l_t': tensor(0.3945), 'sdr_tt': tensor(3.8165)}
[Step]: 1200 | [Train losses]: {'l_g': tensor(1.4351), 'l_d': tensor(0.3812), 'l_t': tensor(0.4379), 'l_f': tensor(0.0001), 'l_w': tensor(71.1077), 'l_feat': tensor(0.8351)}
[Step]: 1200 | [Valid losses]: {'val_l_t': tensor(0.3899), 'sdr_tt': tensor(3.9134)}
[Step]: 1400 | [Train losses]: {'l_g': tensor(1.5695), 'l_d': tensor(0.4133), 'l_t': tensor(0.4014), 'l_f': tensor(4.9736e-05), 'l_w': tensor(69.2972), 'l_feat': tensor(0.7736)}
[Step]: 1400 | [Valid losses]: {'val_l_t': tensor(0.3798), 'sdr_tt': tensor(4.0563)}
[Step]: 1600 | [Train losses]: {'l_g': tensor(1.5679), 'l_d': tensor(0.4617), 'l_t': tensor(0.4377), 'l_f': tensor(6.4874e-05), 'l_w': tensor(66.9259), 'l_feat': tensor(0.7661)}
[Step]: 1600 | [Valid losses]: {'val_l_t': tensor(0.3716), 'sdr_tt': tensor(4.2247)}
[Step]: 1800 | [Train losses]: {'l_g': tensor(1.5596), 'l_d': tensor(0.4077), 'l_t': tensor(0.3877), 'l_f': tensor(5.6210e-05), 'l_w': tensor(61.8045), 'l_feat': tensor(0.7629)}
[Step]: 1800 | [Valid losses]: {'val_l_t': tensor(0.3808), 'sdr_tt': tensor(4.2613)}
[Step]: 2000 | [Train losses]: {'l_g': tensor(1.5581), 'l_d': tensor(0.3761), 'l_t': tensor(0.3879), 'l_f': tensor(5.9083e-05), 'l_w': tensor(59.4422), 'l_feat': tensor(0.7564)}
[Step]: 2000 | [Valid losses]: {'val_l_t': tensor(0.3681), 'sdr_tt': tensor(4.3510)}
[Step]: 2200 | [Train losses]: {'l_g': tensor(1.5911), 'l_d': tensor(0.5266), 'l_t': tensor(0.5130), 'l_f': tensor(6.9784e-05), 'l_w': tensor(73.9039), 'l_feat': tensor(0.7807)}
[Step]: 2200 | [Valid losses]: {'val_l_t': tensor(0.3777), 'sdr_tt': tensor(4.2821)}
[Step]: 2400 | [Train losses]: {'l_g': tensor(1.5451), 'l_d': tensor(0.3785), 'l_t': tensor(0.3901), 'l_f': tensor(5.5415e-05), 'l_w': tensor(59.3155), 'l_feat': tensor(0.7348)}
[Step]: 2400 | [Valid losses]: {'val_l_t': tensor(0.3709), 'sdr_tt': tensor(4.3924)}
[Step]: 2600 | [Train losses]: {'l_g': tensor(1.5927), 'l_d': tensor(0.3753), 'l_t': tensor(0.3779), 'l_f': tensor(5.7392e-05), 'l_w': tensor(57.2983), 'l_feat': tensor(0.7296)}
[Step]: 2600 | [Valid losses]: {'val_l_t': tensor(0.3692), 'sdr_tt': tensor(4.3232)}
[Step]: 2800 | [Train losses]: {'l_g': tensor(1.5898), 'l_d': tensor(0.3769), 'l_t': tensor(0.3736), 'l_f': tensor(6.2736e-05), 'l_w': tensor(53.5857), 'l_feat': tensor(0.7251)}
[Step]: 2800 | [Valid losses]: {'val_l_t': tensor(0.3729), 'sdr_tt': tensor(4.5163)}
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/dist_train.py", line 430, in <module>
    quantizedResult = model.quantizer(emb, sample_rate=frame_rate, bandwidth=inp_args.bandwidth) # !!! should be frame_rate - 50
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/quantization/vq.py", line 82, in forward
    quantized, codes, commit_loss = self.vq(x, n_q=n_q)
                                    ^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/quantization/core_vq.py", line 335, in forward
    quantized, indices, loss = layer(residual)
                               ^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/quantization/core_vq.py", line 298, in forward
    quantize, embed_ind = self._codebook(x)
                          ^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/quantization/core_vq.py", line 219, in forward
    self.expire_codes_(x)
  File "/home/anakuzne/projects/encodec_hy/encodec/code/encodec/quantization/core_vq.py", line 166, in expire_codes_
    batch_samples = rearrange(batch_samples, "... d -> (...) d")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/einops/einops.py", line 483, in rearrange
    return reduce(cast(Tensor, tensor), pattern, reduction='rearrange', **axes_lengths)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/anakuzne/miniconda3/envs/encodec/lib/python3.11/site-packages/einops/einops.py", line 411, in reduce
    recipe = _prepare_transformation_recipe(pattern, reduction, axes_lengths=hashable_axes_lengths)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt